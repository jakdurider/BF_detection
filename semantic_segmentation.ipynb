{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a10abc2-a04b-4596-ae8f-dc4b47025755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15688c4-ff6f-497d-96d5-31964d92d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_values = [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8]  # Gamma values\n",
    "\n",
    "def transform(img):\n",
    "    return img\n",
    "\n",
    "def gamma_correction(img, gamma):\n",
    "    return TF.adjust_gamma(img, gamma)\n",
    "\n",
    "def random_flip(img):\n",
    "    flip_type = random.choice([\"horizontal\", \"vertical\", \"both\", \"none\"])\n",
    "\n",
    "    if flip_type == \"horizontal\":\n",
    "        return TF.hflip(img)\n",
    "    elif flip_type == \"vertical\":\n",
    "        return TF.vflip(img)\n",
    "    elif flip_type == \"both\":\n",
    "        return TF.hflip(TF.vflip(img))\n",
    "    return img  # No flip\n",
    "    \n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "class BleedingDataset(Dataset):\n",
    "    def __init__(self, image_files, transform=None, augmentation=False):\n",
    "        self.image_paths = image_files\n",
    "        self.json_paths = sorted([f.replace('.jpeg', '.json').replace('.png', '.json') for f in self.image_paths])\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "        self.transform_image = transform_image\n",
    "        self.transform_mask = transform_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # JSON ÌååÏùº Î°úÎìú\n",
    "        json_path = self.json_paths[idx]\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Îπà ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±\n",
    "        mask = np.zeros((data[\"imageHeight\"], data[\"imageWidth\"]), dtype=np.uint8)\n",
    "\n",
    "        # Ï∂úÌòà(BF) ÏòÅÏó≠ Ìè¥Î¶¨Í≥§ ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±\n",
    "        for shape in data[\"shapes\"]:\n",
    "            if shape[\"label\"] == \"BF\":\n",
    "                points = np.array(shape[\"points\"], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [points], 255)  # Ï∂úÌòà ÏòÅÏó≠ÏùÑ 255Î°ú ÏÑ§Ï†ï\n",
    "\n",
    "        \n",
    "        # PIL Ïù¥ÎØ∏ÏßÄ Î≥ÄÌôò ÌõÑ Tensor Î≥ÄÌôò\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        image = self.transform_image(image)\n",
    "        mask = self.transform_mask(mask)\n",
    "            \n",
    "        if self.augmentation:\n",
    "            gamma = random.choice(gamma_values)  # ÎûúÎç§Ìïú gamma Í∞í ÏÑ†ÌÉù\n",
    "            image = gamma_correction(image, gamma)\n",
    "            #mask = gamma_correction(mask, gamma)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò Ï†ïÏùò\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BILINEAR),  # ÏùºÎ∞ò Ïù¥ÎØ∏ÏßÄÏö©,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.NEAREST),  # ÏùºÎ∞ò Ïù¥ÎØ∏ÏßÄÏö©,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dice Loss Ï†ïÏùò\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    return 1 - (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n",
    "\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "def focal_loss(pred, target):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    bce_loss = F.binary_cross_entropy(pred, target, reduction='none')\n",
    "    focal_loss = 1 * (1 - torch.exp(-bce_loss)) ** 2 * bce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "def iou_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return 1 - iou  # IoUÍ∞Ä ÎÜíÏùÑÏàòÎ°ù Ï¢ãÍ∏∞ ÎïåÎ¨∏Ïóê, LossÎäî 1ÏóêÏÑú Î∫å\n",
    "\n",
    "def loss_fn(pred, target):\n",
    "    return dice_loss(pred, target) + focal_loss(pred, target) + iou_loss(pred, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ecf573-fb06-4f72-87e4-bf27ad6ed664",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# DeepLabV3Ïùò Ï∂úÎ†• Í∞ÄÏ†∏Ïò§Í∏∞\u001b[39;00m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, masks)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/bf/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/bf/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/bf/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_dir = \"0014_spine_endoscope_data/\"\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpeg', '.png'))])  # Ïù¥ÎØ∏ÏßÄ ÌååÏùº Î¶¨Ïä§Ìä∏\n",
    "\n",
    "# ‚úÖ Train Test Split (85:15 ÎπÑÏú®)\n",
    "train_images, test_images = train_test_split(image_files, test_size=0.15, random_state=42)\n",
    "\n",
    "# train Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è DataLoader ÏÉùÏÑ±\n",
    "train_dataset = BleedingDataset(train_images, transform=transform, augmentation=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# test Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è DataLoader ÏÉùÏÑ±\n",
    "test_dataset = BleedingDataset(test_images, transform=transform, augmentation=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d72e6e-ec99-40ab-9e44-a64c48629706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Î™®Îç∏ Î°úÎìú (ResNet50 Í∏∞Î∞ò)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# Ï∂úÎ†• Ï±ÑÎÑê Î≥ÄÍ≤Ω (COCO ÌÅ¥ÎûòÏä§ ‚Üí Ï∂úÌòà ÌÉêÏßÄ ÌÅ¥ÎûòÏä§ 1Í∞ú)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"deeplabv3_bleeding.pth\"))\n",
    "\n",
    "# GPU ÏÇ¨Ïö© ÏÑ§Ï†ï\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÑ§Ï†ï\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)[\"out\"]  # DeepLabV3Ïùò Ï∂úÎ†• Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Î™®Îç∏ Ï†ÄÏû•\n",
    "torch.save(model.state_dict(), \"deeplabv3_bleeding.pth\")\n",
    "print(\"Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7658874b-8190-4157-82c6-231f64fa756b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BleedingDataset.__init__() got an unexpected keyword argument 'augmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è DataLoader ÏÉùÏÑ±\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mBleedingDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0014_spine_endoscope_label/train_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0014_spine_endoscope_label/train_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Î™®Îç∏ Î°úÎìú (ResNet50 Í∏∞Î∞ò)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: BleedingDataset.__init__() got an unexpected keyword argument 'augmentation'"
     ]
    }
   ],
   "source": [
    "# Î™®Îç∏ Î°úÎìú (ResNet50 Í∏∞Î∞ò)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# Ï∂úÎ†• Ï±ÑÎÑê Î≥ÄÍ≤Ω (COCO ÌÅ¥ÎûòÏä§ ‚Üí Ï∂úÌòà ÌÉêÏßÄ ÌÅ¥ÎûòÏä§ 1Í∞ú)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "model.load_state_dict(torch.load(\"deeplabv3_bleeding.pth\"))\n",
    "\n",
    "# GPU ÏÇ¨Ïö© ÏÑ§Ï†ï\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "output_dir = \"test_results/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "total_num = 0\n",
    "for images, masks in test_dataloader:\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(images)[\"out\"]  # DeepLabV3Ïùò Ï∂úÎ†• Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        \n",
    "    for image, mask, pred in zip(images, masks, preds):\n",
    "        total_num += 1\n",
    "        \n",
    "        # üìå ÌõÑÏ≤òÎ¶¨ (Sigmoid + Threshold)\n",
    "        pred_mask = torch.sigmoid(pred).cpu().numpy()  # (Batch, 1, 512, 512)\n",
    "        pred_mask = (pred_mask > 0.5).astype(np.uint8)  # Ïù¥ÏßÑÌôî\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ, ÎßàÏä§ÌÅ¨ Î≥ÄÌôò\n",
    "        original_image = image.cpu().numpy().transpose(1,2,0)\n",
    "        original_image = (original_image * 255).astype(np.uint8)  # Ï†ïÍ∑úÌôî Ìï¥Ï†ú\n",
    "        original_mask = (mask.squeeze().cpu().numpy() > 0).astype(np.uint8)  # GT ÎßàÏä§ÌÅ¨\n",
    "        pred_mask = pred_mask.squeeze()  # Î™®Îç∏ ÏòàÏ∏° ÎßàÏä§ÌÅ¨\n",
    "\n",
    "\n",
    "        # ‚úÖ Ïª¨Îü¨Îßµ Ï†ÅÏö© (GT = Green, Pred = Red, Overlap = Yellow)\n",
    "        overlay = np.array(original_image)\n",
    "        overlay = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        green = [0, 255, 0]  # Ground Truth (GT) - Green\n",
    "        red = [0, 0, 255]  # Prediction - Red\n",
    "        yellow = [0, 255, 255]  # Overlapping - Yellow\n",
    "\n",
    "        mask_layer = np.zeros_like(overlay, dtype=np.uint8)\n",
    "        mask_layer[original_mask == 1] = green  # GT\n",
    "        mask_layer[pred_mask == 1] = red  # Prediction\n",
    "        mask_layer[(original_mask == 1) & (pred_mask == 1)] = yellow  # Overlap\n",
    "\n",
    "        # ‚úÖ ÏµúÏ¢Ö Ìï©ÏÑ±\n",
    "        blended = cv2.addWeighted(overlay, 0.7, mask_layer, 0.5, 0)\n",
    "\n",
    "        # ‚úÖ Ï†ÄÏû•\n",
    "        filename = f\"output_{total_num}.png\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, blended)\n",
    "        \n",
    "print(\"test completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edcade6-f710-4ab0-9337-6facbced963a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
