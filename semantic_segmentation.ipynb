{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58fac117-6c69-4c60-826c-18bd02c2e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f90a52-8da8-4f99-bcf0-ed989f5441e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_values = [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8]  # Gamma values\n",
    "\n",
    "def transform(img):\n",
    "    return img\n",
    "\n",
    "def gamma_correction(img, gamma):\n",
    "    return TF.adjust_gamma(img, gamma)\n",
    "\n",
    "def random_flip(img):\n",
    "    flip_type = random.choice([\"horizontal\", \"vertical\", \"both\", \"none\"])\n",
    "\n",
    "    if flip_type == \"horizontal\":\n",
    "        return TF.hflip(img)\n",
    "    elif flip_type == \"vertical\":\n",
    "        return TF.vflip(img)\n",
    "    elif flip_type == \"both\":\n",
    "        return TF.hflip(TF.vflip(img))\n",
    "    return img  # No flip\n",
    "    \n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "class BleedingDataset(Dataset):\n",
    "    def __init__(self, image_files, transform=None, augmentation=False):\n",
    "        self.image_paths = image_files\n",
    "        self.json_paths = [f.replace('.jpeg', '.json').replace('.png', '.json') for f in self.image_paths]\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "        self.transform_image = transform_image\n",
    "        self.transform_mask = transform_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # JSON ÌååÏùº Î°úÎìú\n",
    "        json_path = self.json_paths[idx]\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Îπà ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±\n",
    "        mask = np.zeros((data[\"imageHeight\"], data[\"imageWidth\"]), dtype=np.uint8)\n",
    "\n",
    "        # Ï∂úÌòà(BF) ÏòÅÏó≠ Ìè¥Î¶¨Í≥§ ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±\n",
    "        for shape in data[\"shapes\"]:\n",
    "            if shape[\"label\"] == \"BF\":\n",
    "                points = np.array(shape[\"points\"], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [points], 255)  # Ï∂úÌòà ÏòÅÏó≠ÏùÑ 255Î°ú ÏÑ§Ï†ï\n",
    "\n",
    "        \n",
    "        # PIL Ïù¥ÎØ∏ÏßÄ Î≥ÄÌôò ÌõÑ Tensor Î≥ÄÌôò\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        image = self.transform_image(image)\n",
    "        mask = self.transform_mask(mask)\n",
    "            \n",
    "        if self.augmentation:\n",
    "            gamma = random.choice(gamma_values)  # ÎûúÎç§Ìïú gamma Í∞í ÏÑ†ÌÉù\n",
    "            image = gamma_correction(image, gamma)\n",
    "            #mask = gamma_correction(mask, gamma)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò Ï†ïÏùò\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BILINEAR),  # ÏùºÎ∞ò Ïù¥ÎØ∏ÏßÄÏö©,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.NEAREST),  # mask Ïö©,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dice Loss Ï†ïÏùò\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    return 1 - (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n",
    "\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "def focal_loss(pred, target):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    bce_loss = F.binary_cross_entropy(pred, target, reduction='none')\n",
    "    focal_loss = 1 * (1 - torch.exp(-bce_loss)) ** 2 * bce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "def iou_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return 1 - iou  # IoUÍ∞Ä ÎÜíÏùÑÏàòÎ°ù Ï¢ãÍ∏∞ ÎïåÎ¨∏Ïóê, LossÎäî 1ÏóêÏÑú Î∫å\n",
    "\n",
    "def loss_fn(pred, target):\n",
    "    return (dice_loss(pred, target) + focal_loss(pred, target) + iou_loss(pred, target)) / 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed21a7c3-cd1b-472d-b3b3-93d226e5afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"0014_spine_endoscope_data/\"\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpeg', '.png'))])  # Ïù¥ÎØ∏ÏßÄ ÌååÏùº Î¶¨Ïä§Ìä∏\n",
    "\n",
    "# ‚úÖ Train Test Split (85:15 ÎπÑÏú®)\n",
    "train_images, test_images = train_test_split(image_files, test_size=0.15, random_state=42)\n",
    "\n",
    "# train Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è DataLoader ÏÉùÏÑ±\n",
    "train_dataset = BleedingDataset(train_images, transform=transform, augmentation=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# test Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è DataLoader ÏÉùÏÑ±\n",
    "test_dataset = BleedingDataset(test_images, transform=transform, augmentation=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b34cfa73-959e-41f8-97c7-841efc2f479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3148\n",
      "Epoch [2/10], Loss: 0.3043\n",
      "Epoch [3/10], Loss: 0.3031\n",
      "Epoch [4/10], Loss: 0.2919\n",
      "Epoch [5/10], Loss: 0.2959\n",
      "Epoch [6/10], Loss: 0.2939\n",
      "Epoch [7/10], Loss: 0.3002\n",
      "Epoch [8/10], Loss: 0.2903\n",
      "Epoch [9/10], Loss: 0.2857\n",
      "Epoch [10/10], Loss: 0.2656\n",
      "Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Î™®Îç∏ Î°úÎìú (ResNet50 Í∏∞Î∞ò)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# Ï∂úÎ†• Ï±ÑÎÑê Î≥ÄÍ≤Ω (COCO ÌÅ¥ÎûòÏä§ ‚Üí Ï∂úÌòà ÌÉêÏßÄ ÌÅ¥ÎûòÏä§ 1Í∞ú)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "model.load_state_dict(torch.load(\"deeplabv3_bleeding.pth\"))\n",
    "\n",
    "# GPU ÏÇ¨Ïö© ÏÑ§Ï†ï\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÑ§Ï†ï\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)[\"out\"]  # DeepLabV3Ïùò Ï∂úÎ†• Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Î™®Îç∏ Ï†ÄÏû•\n",
    "torch.save(model.state_dict(), \"deeplabv3_bleeding.pth\")\n",
    "print(\"Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d53d084-fcea-44b8-be32-e7eb4ef9c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Î™®Îç∏ Î°úÎìú (ResNet50 Í∏∞Î∞ò)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# Ï∂úÎ†• Ï±ÑÎÑê Î≥ÄÍ≤Ω (COCO ÌÅ¥ÎûòÏä§ ‚Üí Ï∂úÌòà ÌÉêÏßÄ ÌÅ¥ÎûòÏä§ 1Í∞ú)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "model.load_state_dict(torch.load(\"deeplabv3_bleeding.pth\"))\n",
    "\n",
    "# GPU ÏÇ¨Ïö© ÏÑ§Ï†ï\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "output_dir = \"test_results2/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "total_num = 0\n",
    "for images, masks in test_dataloader:\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(images)[\"out\"]  # DeepLabV3Ïùò Ï∂úÎ†• Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        \n",
    "    for image, mask, pred in zip(images, masks, preds):\n",
    "        total_num += 1\n",
    "        \n",
    "        # üìå ÌõÑÏ≤òÎ¶¨ (Sigmoid + Threshold)\n",
    "        pred_mask = torch.sigmoid(pred).cpu().numpy()  # (Batch, 1, 512, 512)\n",
    "        pred_mask = (pred_mask > 0.5).astype(np.uint8)  # Ïù¥ÏßÑÌôî\n",
    "        \n",
    "        # ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ, ÎßàÏä§ÌÅ¨ Î≥ÄÌôò\n",
    "        original_image = image.cpu().numpy().transpose(1,2,0)\n",
    "        original_image = (original_image * 255).astype(np.uint8)  # Ï†ïÍ∑úÌôî Ìï¥Ï†ú\n",
    "        original_mask = (mask.squeeze().cpu().numpy() > 0).astype(np.uint8)  # GT ÎßàÏä§ÌÅ¨\n",
    "        pred_mask = pred_mask.squeeze()  # Î™®Îç∏ ÏòàÏ∏° ÎßàÏä§ÌÅ¨\n",
    "        \n",
    "        # ‚úÖ Ïª¨Îü¨Îßµ Ï†ÅÏö© (GT = Green, Pred = Red, Overlap = Yellow)\n",
    "        overlay = np.array(original_image)\n",
    "        overlay = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        green = [0, 255, 0]  # Ground Truth (GT) - Green\n",
    "        red = [0, 0, 255]  # Prediction - Red\n",
    "        yellow = [0, 255, 255]  # Overlapping - Yellow\n",
    "\n",
    "        mask_layer = np.zeros_like(overlay, dtype=np.uint8)\n",
    "        mask_layer[original_mask == 1] = green  # GT\n",
    "        mask_layer[pred_mask == 1] = red  # Prediction\n",
    "        mask_layer[(original_mask == 1) & (pred_mask == 1)] = yellow  # Overlap\n",
    "\n",
    "        # ‚úÖ ÏµúÏ¢Ö Ìï©ÏÑ±\n",
    "        blended = cv2.addWeighted(overlay, 0.7, mask_layer, 0.5, 0)\n",
    "\n",
    "        # blended = cv2.resize(blended, (1920, 1080), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "        # ‚úÖ Ï†ÄÏû•\n",
    "        filename = f\"output_{total_num}.png\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, blended)\n",
    "        \n",
    "print(\"test completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf9f98-6ee8-484e-a577-d098b8d2501b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
