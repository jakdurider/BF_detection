{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58fac117-6c69-4c60-826c-18bd02c2e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f90a52-8da8-4f99-bcf0-ed989f5441e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_values = [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8]  # Gamma values\n",
    "\n",
    "def transform(img):\n",
    "    return img\n",
    "\n",
    "def gamma_correction(img, gamma):\n",
    "    return TF.adjust_gamma(img, gamma)\n",
    "\n",
    "def random_flip(img):\n",
    "    flip_type = random.choice([\"horizontal\", \"vertical\", \"both\", \"none\"])\n",
    "\n",
    "    if flip_type == \"horizontal\":\n",
    "        return TF.hflip(img)\n",
    "    elif flip_type == \"vertical\":\n",
    "        return TF.vflip(img)\n",
    "    elif flip_type == \"both\":\n",
    "        return TF.hflip(TF.vflip(img))\n",
    "    return img  # No flip\n",
    "    \n",
    "# 데이터셋 클래스 정의\n",
    "class BleedingDataset(Dataset):\n",
    "    def __init__(self, image_files, transform=None, augmentation=False):\n",
    "        self.image_paths = image_files\n",
    "        self.json_paths = [f.replace('.jpeg', '.json').replace('.png', '.json') for f in self.image_paths]\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "        self.transform_image = transform_image\n",
    "        self.transform_mask = transform_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 원본 이미지 로드\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # JSON 파일 로드\n",
    "        json_path = self.json_paths[idx]\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # 빈 마스크 생성\n",
    "        mask = np.zeros((data[\"imageHeight\"], data[\"imageWidth\"]), dtype=np.uint8)\n",
    "\n",
    "        # 출혈(BF) 영역 폴리곤 마스크 생성\n",
    "        for shape in data[\"shapes\"]:\n",
    "            if shape[\"label\"] == \"BF\":\n",
    "                points = np.array(shape[\"points\"], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [points], 255)  # 출혈 영역을 255로 설정\n",
    "\n",
    "        \n",
    "        # PIL 이미지 변환 후 Tensor 변환\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        image = self.transform_image(image)\n",
    "        mask = self.transform_mask(mask)\n",
    "            \n",
    "        if self.augmentation:\n",
    "            gamma = random.choice(gamma_values)  # 랜덤한 gamma 값 선택\n",
    "            image = gamma_correction(image, gamma)\n",
    "            #mask = gamma_correction(mask, gamma)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BILINEAR),  # 일반 이미지용,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.NEAREST),  # mask 용,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dice Loss 정의\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    return 1 - (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n",
    "\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "def focal_loss(pred, target):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    bce_loss = F.binary_cross_entropy(pred, target, reduction='none')\n",
    "    focal_loss = 1 * (1 - torch.exp(-bce_loss)) ** 2 * bce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "def iou_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return 1 - iou  # IoU가 높을수록 좋기 때문에, Loss는 1에서 뺌\n",
    "\n",
    "def loss_fn(pred, target):\n",
    "    return (dice_loss(pred, target) + focal_loss(pred, target) + iou_loss(pred, target)) / 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed21a7c3-cd1b-472d-b3b3-93d226e5afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"0014_spine_endoscope_data/\"\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpeg', '.png'))])  # 이미지 파일 리스트\n",
    "\n",
    "# ✅ Train Test Split (85:15 비율)\n",
    "train_images, test_images = train_test_split(image_files, test_size=0.15, random_state=42)\n",
    "\n",
    "# train 데이터셋 및 DataLoader 생성\n",
    "train_dataset = BleedingDataset(train_images, transform=transform, augmentation=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# test 데이터셋 및 DataLoader 생성\n",
    "test_dataset = BleedingDataset(test_images, transform=transform, augmentation=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b34cfa73-959e-41f8-97c7-841efc2f479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3148\n",
      "Epoch [2/10], Loss: 0.3043\n",
      "Epoch [3/10], Loss: 0.3031\n",
      "Epoch [4/10], Loss: 0.2919\n",
      "Epoch [5/10], Loss: 0.2959\n",
      "Epoch [6/10], Loss: 0.2939\n",
      "Epoch [7/10], Loss: 0.3002\n",
      "Epoch [8/10], Loss: 0.2903\n",
      "Epoch [9/10], Loss: 0.2857\n",
      "Epoch [10/10], Loss: 0.2656\n",
      "모델 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 로드 (ResNet50 기반)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# 출력 채널 변경 (COCO 클래스 → 출혈 탐지 클래스 1개)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "model.load_state_dict(torch.load(\"deeplabv3_bleeding.pth\"))\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)[\"out\"]  # DeepLabV3의 출력 가져오기\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), \"deeplabv3_bleeding.pth\")\n",
    "print(\"모델 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d53d084-fcea-44b8-be32-e7eb4ef9c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 로드 (ResNet50 기반)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# 출력 채널 변경 (COCO 클래스 → 출혈 탐지 클래스 1개)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "model.load_state_dict(torch.load(\"deeplabv3_bleeding.pth\"))\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "output_dir = \"test_results2/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "total_num = 0\n",
    "for images, masks in test_dataloader:\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(images)[\"out\"]  # DeepLabV3의 출력 가져오기\n",
    "        \n",
    "    for image, mask, pred in zip(images, masks, preds):\n",
    "        total_num += 1\n",
    "        \n",
    "        # 📌 후처리 (Sigmoid + Threshold)\n",
    "        pred_mask = torch.sigmoid(pred).cpu().numpy()  # (Batch, 1, 512, 512)\n",
    "        pred_mask = (pred_mask > 0.5).astype(np.uint8)  # 이진화\n",
    "        \n",
    "        # 원본 이미지, 마스크 변환\n",
    "        original_image = image.cpu().numpy().transpose(1,2,0)\n",
    "        original_image = (original_image * 255).astype(np.uint8)  # 정규화 해제\n",
    "        original_mask = (mask.squeeze().cpu().numpy() > 0).astype(np.uint8)  # GT 마스크\n",
    "        pred_mask = pred_mask.squeeze()  # 모델 예측 마스크\n",
    "        \n",
    "        # ✅ 컬러맵 적용 (GT = Green, Pred = Red, Overlap = Yellow)\n",
    "        overlay = np.array(original_image)\n",
    "        overlay = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        green = [0, 255, 0]  # Ground Truth (GT) - Green\n",
    "        red = [0, 0, 255]  # Prediction - Red\n",
    "        yellow = [0, 255, 255]  # Overlapping - Yellow\n",
    "\n",
    "        mask_layer = np.zeros_like(overlay, dtype=np.uint8)\n",
    "        mask_layer[original_mask == 1] = green  # GT\n",
    "        mask_layer[pred_mask == 1] = red  # Prediction\n",
    "        mask_layer[(original_mask == 1) & (pred_mask == 1)] = yellow  # Overlap\n",
    "\n",
    "        # ✅ 최종 합성\n",
    "        blended = cv2.addWeighted(overlay, 0.7, mask_layer, 0.5, 0)\n",
    "\n",
    "        # blended = cv2.resize(blended, (1920, 1080), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "        # ✅ 저장\n",
    "        filename = f\"output_{total_num}.png\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, blended)\n",
    "        \n",
    "print(\"test completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf9f98-6ee8-484e-a577-d098b8d2501b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
