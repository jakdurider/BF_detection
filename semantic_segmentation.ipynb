{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a10abc2-a04b-4596-ae8f-dc4b47025755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15688c4-ff6f-497d-96d5-31964d92d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_values = [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8]  # Gamma values\n",
    "\n",
    "def transform(img):\n",
    "    return img\n",
    "\n",
    "def gamma_correction(img, gamma):\n",
    "    return TF.adjust_gamma(img, gamma)\n",
    "\n",
    "def random_flip(img):\n",
    "    flip_type = random.choice([\"horizontal\", \"vertical\", \"both\", \"none\"])\n",
    "\n",
    "    if flip_type == \"horizontal\":\n",
    "        return TF.hflip(img)\n",
    "    elif flip_type == \"vertical\":\n",
    "        return TF.vflip(img)\n",
    "    elif flip_type == \"both\":\n",
    "        return TF.hflip(TF.vflip(img))\n",
    "    return img  # No flip\n",
    "    \n",
    "# 데이터셋 클래스 정의\n",
    "class BleedingDataset(Dataset):\n",
    "    def __init__(self, image_files, transform=None, augmentation=False):\n",
    "        self.image_paths = image_files\n",
    "        self.json_paths = sorted([f.replace('.jpeg', '.json').replace('.png', '.json') for f in self.image_paths])\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "        self.transform_image = transform_image\n",
    "        self.transform_mask = transform_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 원본 이미지 로드\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # JSON 파일 로드\n",
    "        json_path = self.json_paths[idx]\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # 빈 마스크 생성\n",
    "        mask = np.zeros((data[\"imageHeight\"], data[\"imageWidth\"]), dtype=np.uint8)\n",
    "\n",
    "        # 출혈(BF) 영역 폴리곤 마스크 생성\n",
    "        for shape in data[\"shapes\"]:\n",
    "            if shape[\"label\"] == \"BF\":\n",
    "                points = np.array(shape[\"points\"], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [points], 255)  # 출혈 영역을 255로 설정\n",
    "\n",
    "        \n",
    "        # PIL 이미지 변환 후 Tensor 변환\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        image = self.transform_image(image)\n",
    "        mask = self.transform_mask(mask)\n",
    "            \n",
    "        if self.augmentation:\n",
    "            gamma = random.choice(gamma_values)  # 랜덤한 gamma 값 선택\n",
    "            image = gamma_correction(image, gamma)\n",
    "            #mask = gamma_correction(mask, gamma)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# 데이터 변환 정의\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BILINEAR),  # 일반 이미지용,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.NEAREST),  # 일반 이미지용,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dice Loss 정의\n",
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    return 1 - (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n",
    "\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "def focal_loss(pred, target):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    bce_loss = F.binary_cross_entropy(pred, target, reduction='none')\n",
    "    focal_loss = 1 * (1 - torch.exp(-bce_loss)) ** 2 * bce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "def iou_loss(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return 1 - iou  # IoU가 높을수록 좋기 때문에, Loss는 1에서 뺌\n",
    "\n",
    "def loss_fn(pred, target):\n",
    "    return dice_loss(pred, target) + focal_loss(pred, target) + iou_loss(pred, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ecf573-fb06-4f72-87e4-bf27ad6ed664",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# DeepLabV3의 출력 가져오기\u001b[39;00m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, masks)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/bf/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/bf/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/bf/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_dir = \"0014_spine_endoscope_data/\"\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpeg', '.png'))])  # 이미지 파일 리스트\n",
    "\n",
    "# ✅ Train Test Split (85:15 비율)\n",
    "train_images, test_images = train_test_split(image_files, test_size=0.15, random_state=42)\n",
    "\n",
    "# train 데이터셋 및 DataLoader 생성\n",
    "train_dataset = BleedingDataset(train_images, transform=transform, augmentation=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# test 데이터셋 및 DataLoader 생성\n",
    "test_dataset = BleedingDataset(test_images, transform=transform, augmentation=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d72e6e-ec99-40ab-9e44-a64c48629706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 로드 (ResNet50 기반)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# 출력 채널 변경 (COCO 클래스 → 출혈 탐지 클래스 1개)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"deeplabv3_bleeding.pth\"))\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)[\"out\"]  # DeepLabV3의 출력 가져오기\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), \"deeplabv3_bleeding.pth\")\n",
    "print(\"모델 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7658874b-8190-4157-82c6-231f64fa756b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BleedingDataset.__init__() got an unexpected keyword argument 'augmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 데이터셋 및 DataLoader 생성\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mBleedingDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0014_spine_endoscope_label/train_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0014_spine_endoscope_label/train_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 모델 로드 (ResNet50 기반)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: BleedingDataset.__init__() got an unexpected keyword argument 'augmentation'"
     ]
    }
   ],
   "source": [
    "# 모델 로드 (ResNet50 기반)\n",
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# 출력 채널 변경 (COCO 클래스 → 출혈 탐지 클래스 1개)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "model.load_state_dict(torch.load(\"deeplabv3_bleeding.pth\"))\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "output_dir = \"test_results/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "total_num = 0\n",
    "for images, masks in test_dataloader:\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = model(images)[\"out\"]  # DeepLabV3의 출력 가져오기\n",
    "        \n",
    "    for image, mask, pred in zip(images, masks, preds):\n",
    "        total_num += 1\n",
    "        \n",
    "        # 📌 후처리 (Sigmoid + Threshold)\n",
    "        pred_mask = torch.sigmoid(pred).cpu().numpy()  # (Batch, 1, 512, 512)\n",
    "        pred_mask = (pred_mask > 0.5).astype(np.uint8)  # 이진화\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 원본 이미지, 마스크 변환\n",
    "        original_image = image.cpu().numpy().transpose(1,2,0)\n",
    "        original_image = (original_image * 255).astype(np.uint8)  # 정규화 해제\n",
    "        original_mask = (mask.squeeze().cpu().numpy() > 0).astype(np.uint8)  # GT 마스크\n",
    "        pred_mask = pred_mask.squeeze()  # 모델 예측 마스크\n",
    "\n",
    "\n",
    "        # ✅ 컬러맵 적용 (GT = Green, Pred = Red, Overlap = Yellow)\n",
    "        overlay = np.array(original_image)\n",
    "        overlay = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        green = [0, 255, 0]  # Ground Truth (GT) - Green\n",
    "        red = [0, 0, 255]  # Prediction - Red\n",
    "        yellow = [0, 255, 255]  # Overlapping - Yellow\n",
    "\n",
    "        mask_layer = np.zeros_like(overlay, dtype=np.uint8)\n",
    "        mask_layer[original_mask == 1] = green  # GT\n",
    "        mask_layer[pred_mask == 1] = red  # Prediction\n",
    "        mask_layer[(original_mask == 1) & (pred_mask == 1)] = yellow  # Overlap\n",
    "\n",
    "        # ✅ 최종 합성\n",
    "        blended = cv2.addWeighted(overlay, 0.7, mask_layer, 0.5, 0)\n",
    "\n",
    "        # ✅ 저장\n",
    "        filename = f\"output_{total_num}.png\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, blended)\n",
    "        \n",
    "print(\"test completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edcade6-f710-4ab0-9337-6facbced963a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
